{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "# vocabulary\n",
    "V = set(tokens)\n",
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emission Probabilities\n",
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VERB    0.088410\n",
       "CONJ    0.057862\n",
       "ADP     0.090207\n",
       "NUM     0.081132\n",
       "DET     0.172866\n",
       ".       0.094429\n",
       "X       0.026235\n",
       "PRT     0.002336\n",
       "ADV     0.052561\n",
       "ADJ     0.044564\n",
       "NOUN    0.223360\n",
       "PRON    0.065948\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = sorted(list(set([pair[1] for pair in train_bag])))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on entire 5% test dataset.\n",
    "# Assigning 5% test_set to test_run\n",
    "\n",
    "test_run = test_set\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq = Viterbi(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050608081600627"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 1 Rule Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To improve the performance,we specify a rule base tagger for unknown words \n",
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    " \n",
    "# Assigning regex patterns for rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_Mod1_Rule(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = sorted(list(set([pair[1] for pair in train_bag])))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "        \n",
    "         \n",
    "        if(pmax==0): #For Unknown words using rule based tagger as emission probability will be 0\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # For Known words Assigning state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "             \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Techniquie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_mod1 = Viterbi_Mod1_Rule(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9501765398195371"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check1 = [i for i, j in zip(tagged_seq_mod1, test_run_base) if i == j] \n",
    "\n",
    "accuracy1 = len(check1)/len(tagged_seq_mod1)\n",
    "\n",
    "accuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 2 Consider only Transition Probabaility for Unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_Mod2_Rule(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = sorted(list(set([pair[1] for pair in train_bag])))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            \n",
    "            if emission_p != 0: \n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "            else: # when word does not exist\n",
    "                state_probability = 0.00001 * transition_p\n",
    "                p.append(state_probability)\n",
    "            \n",
    "             \n",
    "                     \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum     \n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Technique 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_mod2 = Viterbi_Mod2_Rule(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321302471557473"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check2 = [i for i, j in zip(tagged_seq_mod2, test_run_base) if i == j] \n",
    "\n",
    "accuracy2 = len(check2)/len(tagged_seq_mod2)\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 3 Additive Smooting and Assigning Noun (Most Frequent) POS Tag for Unknown Tags Apart from Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_Mod3_Rule(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = sorted(list(set([pair[1] for pair in train_bag])))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            \n",
    "            lambda_laplace = 0.00001 # Additive smooting\n",
    "     \n",
    "            state_probability = (emission_p * transition_p) + lambda_laplace\n",
    "            \n",
    "           \n",
    "            p.append(state_probability)\n",
    "             \n",
    "                     \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum     \n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        #Creating a df to change the unknown tags to most frequent tags\n",
    "        data_tuples = list(zip(words, state))\n",
    "        DF_Mod = pd.DataFrame(data_tuples, columns=['words','state'])\n",
    "        DF_Mod.loc[(DF_Mod['words'] != \".\") & (DF_Mod['words'] != \",\") & (DF_Mod['state'] == \".\") , 'newstate'] = 'NOUN'\n",
    "        DF_Mod.loc[(DF_Mod['words'] == \".\")  & (DF_Mod['state'] == \".\") , 'newstate'] = '.'\n",
    "        DF_Mod.loc[(DF_Mod['words'] == \",\")  & (DF_Mod['state'] == \".\") , 'newstate'] = '.'\n",
    "        DF_Mod.loc[(DF_Mod['state'] != \".\") , 'newstate'] = DF_Mod['state']\n",
    "        DF_Mod = DF_Mod[['words', 'newstate']]\n",
    "        words1 = DF_Mod['words'].tolist()\n",
    "        state1 = DF_Mod['newstate'].tolist()\n",
    "\n",
    "    return list(zip(words1, state1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Technique 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_mod3 = Viterbi_Mod3_Rule(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056492742251864"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check3 = [i for i, j in zip(tagged_seq_mod3, test_run_base) if i == j] \n",
    "\n",
    "accuracy3 = len(check3)/len(tagged_seq_mod3)\n",
    "\n",
    "accuracy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla Viterbi  = 90.5 %\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique 1      = 95 % (Rule Based)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique 2      = 93.2 % (Consider only Transition Probabaility for Unknown words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique 3      = 90.5 % (Additive Smooting + Assigning Noun (Most Frequent) POS Tag for Unknown Tags Apart from Punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Sentence 1\n",
    "sentence_test1 = 'Android is a mobile operating system developed by Google.'\n",
    "words1 = word_tokenize(sentence_test1)\n",
    "\n",
    "\n",
    "Test11 = Viterbi(words1)\n",
    "Test12 = Viterbi_Mod1_Rule(words1)\n",
    "Test13 = Viterbi_Mod2_Rule(words1)\n",
    "Test14 = Viterbi_Mod3_Rule(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', '.'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', '.'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(Test11)\n",
    "print(Test12)\n",
    "print(Test13)\n",
    "print(Test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Sentence 2\n",
    "sentence_test2 = 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'\n",
    "words2 = word_tokenize(sentence_test2)\n",
    "\n",
    "\n",
    "Test21 = Viterbi(words2)\n",
    "Test22 = Viterbi_Mod1_Rule(words2)\n",
    "Test23 = Viterbi_Mod2_Rule(words2)\n",
    "Test24 = Viterbi_Mod3_Rule(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', '.'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', '.'), ('worldwide', '.'), ('on', 'ADP'), ('smartphones', '.'), ('since', 'ADP'), ('2011', '.'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', '.'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.')]\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(Test21)\n",
    "print(Test22)\n",
    "print(Test23)\n",
    "print(Test24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Sentence 3\n",
    "sentence_test3 = \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\"\n",
    "words3 = word_tokenize(sentence_test3)\n",
    "\n",
    "\n",
    "Test31 = Viterbi(words3)\n",
    "Test32 = Viterbi_Mod1_Rule(words3)\n",
    "Test33 = Viterbi_Mod2_Rule(words3)\n",
    "Test34 = Viterbi_Mod3_Rule(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', '.'), ('and', 'CONJ'), ('Twitter', '.'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', '.'), ('that', 'DET'), ('gave', 'VERB'), ('Google', '.'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', '.'), (\"'s\", 'VERB'), ('firehose', '.'), ('.', '.')]\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.')]\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.')]\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'VERB'), ('firehose', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(Test31)\n",
    "print(Test32)\n",
    "print(Test33)\n",
    "print(Test34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence_1 = 'Android is a mobile operating system developed by Google.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence_2 = 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence_3 = \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Above three sentences has unknown words  from sample test file which Vanilla Viterbi Algorithm was not able tag correctly. Rule based modifed Viterbi has given the best accuracy of 95% and has tagged the above sentences correctly. Technique 2 where we considered only Transition probability for Unknown words has given a accuracy of 93% and tagged above sentences partially correctly. Technique 3 using additive smooting and assigning Most frequent POS Tag to unknown words except punctuation has also been quite effective in handling these sentences though its accuracy of 90.5% which is almost the same as Vanilla Viterbi ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
